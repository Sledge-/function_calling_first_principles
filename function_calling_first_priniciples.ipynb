{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import boto3\n",
    "from utils import bedrock, print_ww\n",
    "from utils.utils import extract_model_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up Bedrock API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create new client\n",
      "  Using region: None\n",
      "boto3 Bedrock client successfully created!\n",
      "bedrock(https://bedrock.us-east-1.amazonaws.com)\n"
     ]
    }
   ],
   "source": [
    "boto3_bedrock = bedrock.get_bedrock_client(\n",
    "    assumed_role=os.environ.get(\"BEDROCK_ASSUME_ROLE\", None),\n",
    "    region=os.environ.get(\"AWS_DEFAULT_REGION\", None),\n",
    "    runtime=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's take a look at which models we have access to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extract_model_info(all_models): [('Titan Text Large', 'amazon.titan-tg1-large'), ('Titan Text Embeddings', 'amazon.titan-e1t-medium'), ('Titan Text Embeddings v2', 'amazon.titan-embed-g1-text-02'), ('Titan Text G1 - Express', 'amazon.titan-text-express-v1'), ('Titan Embeddings G1 - Text', 'amazon.titan-embed-text-v1'), ('Stable Diffusion XL', 'stability.stable-diffusion-xl'), ('Stable Diffusion XL', 'stability.stable-diffusion-xl-v0'), ('J2 Grande Instruct', 'ai21.j2-grande-instruct'), ('J2 Jumbo Instruct', 'ai21.j2-jumbo-instruct'), ('Jurassic-2 Mid', 'ai21.j2-mid'), ('Jurassic-2 Mid', 'ai21.j2-mid-v1'), ('Jurassic-2 Ultra', 'ai21.j2-ultra'), ('Jurassic-2 Ultra', 'ai21.j2-ultra-v1'), ('Claude Instant', 'anthropic.claude-instant-v1'), ('Claude', 'anthropic.claude-v1'), ('Claude V1 100k', 'anthropic.claude-v1-100k'), ('Claude', 'anthropic.claude-v2'), ('Claude V2 100k', 'anthropic.claude-v2-100k'), ('Command', 'cohere.command-text-v14')]\n"
     ]
    }
   ],
   "source": [
    "all_models = boto3_bedrock.list_foundation_models()\n",
    "print(f\"extract_model_info(all_models): {extract_model_info(all_models)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create new client\n",
      "  Using region: None\n",
      "boto3 Bedrock client successfully created!\n",
      "bedrock-runtime(https://bedrock-runtime.us-east-1.amazonaws.com)\n"
     ]
    }
   ],
   "source": [
    "bedrock_runtime = bedrock.get_bedrock_client(\n",
    "    assumed_role=os.environ.get(\"BEDROCK_ASSUME_ROLE\", None),\n",
    "    region=os.environ.get(\"AWS_DEFAULT_REGION\", None)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_data = \"\"\"\n",
    "Human: Tell me everything you know about JSON schema.\n",
    "\n",
    "Assistant:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = json.dumps({\"prompt\": prompt_data, \"max_tokens_to_sample\": 500})\n",
    "modelId = \"anthropic.claude-v2\" \n",
    "accept = \"application/json\"\n",
    "contentType = \"application/json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Here is a summary of what I know about JSON schema:\n",
      "\n",
      "- JSON schema is a vocabulary that allows you to annotate and validate JSON documents. It defines a JSON-based format to describe the structure of JSON data.\n",
      "\n",
      "- JSON schemas are JSON documents themselves that describe JSON data using validation keywords like \"type\", \"properties\", \"required\", etc. These keywords provide rules that JSON documents being validated must adhere to.\n",
      "\n",
      "- A JSON schema can be used to validate if a JSON document follows the schema, which is useful for data validation and clarifying expectations for JSON data you are consuming or producing. \n",
      "\n",
      "- Some common things JSON schema validation checks:\n",
      "    - Valid data types (string, number, boolean, etc)\n",
      "    - Required properties\n",
      "    - String length limits\n",
      "    - Value ranges for numbers\n",
      "    - Expected object structure/hierarchy\n",
      "    - Referencing definitions for reused JSON structures\n",
      "\n",
      "- There are several JSON schema specification versions (draft-04, draft-06, draft-07, etc). Later drafts add more validation features.\n",
      "\n",
      "- JSON schema validators like AJV can programmatically validate JSON against a JSON schema and report any violations. This is useful in API request/response validation.\n",
      "\n",
      "- JSON schema definitions can provide useful documentation and clarity around the shape of JSON data being used in applications.\n",
      "\n",
      "- JSON schema is commonly used for configuration file validation, API request/response validation, documenting APIs that use JSON, and more.\n"
     ]
    }
   ],
   "source": [
    "response = bedrock_runtime.invoke_model(\n",
    "    body=body, modelId=modelId, accept=accept, contentType=contentType\n",
    ")\n",
    "response_body = json.loads(response.get(\"body\").read())\n",
    "\n",
    "print(response_body.get(\"completion\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_data = \"\"\"\n",
    "Human: Your role is to form function arguments based on the specification provide in 'FUNCTIONS'.  Users will ask you a question about the weather, and you'll attempt to form the function call that we can pass along to a tool to determine the response. Do not try to answer questions about the weather directly, use the provided tools.  The tools are specified using a json schema format, which defines how the arguments to the function are to be formed.\n",
    "\n",
    "FUNCTIONS = [\n",
    "    {\n",
    "        \"name\": \"get_current_weather\",\n",
    "        \"description\": \"Get the current weather\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                },\n",
    "                \"format\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                    \"description\": \"The temperature unit to use. Infer this from the users location.\",\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"location\", \"format\"],\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "Examples\n",
    "###\n",
    "Human: \n",
    "What's the weather like in Glasgow Scotland?\n",
    "Assistant:\n",
    "{\n",
    "'function_call': {'name': 'get_current_weather',\n",
    "    'arguments': {\n",
    "        \"location\": \"Glasgow, Scotland\",\n",
    "        \"format\": \"celsius\"\n",
    "    }\n",
    "}\n",
    "\n",
    "Human: \n",
    "What's the weather like in Raleigh, NC?\n",
    "Assistant:\n",
    "{\n",
    "'function_call': {'name': 'get_current_weather',\n",
    "    'arguments': {\n",
    "        \"location\": \"Raleigh, North Carolina\",\n",
    "        \"format\": \"fahrenheit\"\n",
    "    }\n",
    "}\n",
    "###\n",
    "\n",
    "Human:\n",
    "What's the weather like in Washington, DC?\n",
    "\n",
    "Assistant:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = json.dumps({\"prompt\": prompt_data, \"max_tokens_to_sample\": 500})\n",
    "modelId = \"anthropic.claude-v2\" \n",
    "accept = \"application/json\"\n",
    "contentType = \"application/json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Here is the function call to get the current weather in Washington, DC:\n",
      "\n",
      "{\n",
      "  \"function_call\": {\n",
      "    \"name\": \"get_current_weather\", \n",
      "    \"arguments\": {\n",
      "      \"location\": \"Washington, DC\",\n",
      "      \"format\": \"fahrenheit\"\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = bedrock_runtime.invoke_model(\n",
    "    body=body, modelId=modelId, accept=accept, contentType=contentType\n",
    ")\n",
    "response_body = json.loads(response.get(\"body\").read())\n",
    "\n",
    "print(response_body.get(\"completion\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# And Now for the Main Event.\n",
    "\n",
    "Here's a class that prompts a language model for function arguments for a linear regression, based on data that we load into the context from and external source.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompt_template import PromptTemplate, load_text_file\n",
    "from function_parser import FunctionParser\n",
    "from linear_trend_model import run_linear_trend_model, FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#: Here's our prompt that we'll use to drive the language model\n",
    "linear_trend_prompt = load_text_file('linear_trend_request.prompt')\n",
    "\n",
    "#: Here's a mock article excerpt that I generated to showcase this technology.\n",
    "city_dogs =  load_text_file('city_dogs.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear_trend_filled_prompt: Human:\n",
      "\n",
      "You will play the role of an expert Data Scientist assistant.  You love linear models, and when you get linear data you make a function call to fit a model to the data. We'll use triple hash ### to open and close subsections of prompt examples.\n",
      "\n",
      "We're going to define your character and behaviour in terms of the red, yellow, blue, and green color categories that relate to personality types.\n",
      "\n",
      "The color system I'm referring to - it's a way of categorizing personality traits into four colors:\n",
      "\n",
      "Red personalities are usually seen as bold, expressive, and competitive. They are motivated by power, stimulation, and winning.\n",
      "Yellow personalities are sociable, outgoing, and enthusiastic. They tend to be persuasive, verbal, and eager to collaborate.\n",
      "Green personalities are calm, accommodating, and caring. They value stability, compassion, and building community.\n",
      "Blue personalities are logical, detail-oriented, and focused. They are quantitative, deliberate, and good at reasoning analytically.\n",
      "\n",
      "You are a blue personality no matter what anyone else tries to tell you.\n",
      "\n",
      "Your role is to form function arguments based on the specification provide in 'FUNCTIONS'.  Users will send you data that contains prose with certain numeric quantities described in various ways. Do not try to answer questions about the numbers directly, use the provided tools.  The tools are specified using a json schema format, which defines how the arguments to the function are to be formed.  \n",
      "\n",
      "Here are the json schema definitions for the functions provided to you.\n",
      "FUNCTIONS:\n",
      "###\n",
      "[{'name': 'run_linear_trend_model', 'description': 'This function runs a linear regression from two lists x,y which contain numeric data.', 'properties': {'x': {'type': 'array', 'items': {'type': 'number'}, 'description': 'List of numeric values representing the independent variable.'}, 'y': {'type': 'array', 'items': {'type': 'number'}, 'description': 'List of numeric values representing the dependent variable.'}}, 'required': ['x', 'y']}]\n",
      "###\n",
      "\n",
      "You will form the arguments to a function that calls a linear regression model.  Try to put time spacial and time orderd variables on the x axis, and things like metrics and KPIs on the vertical axis.  When in doubt, just do the best you can.\n",
      "\n",
      "Here's a few example input/output pair:\n",
      "###\n",
      "Example 1:\n",
      "There was once a fox that ran 20 miles carrying 15 pounds.  There was a wold that ran 25 miles carrying 30 pounds.  A turtle loped along slowly, hauling 50 pounds a totla of 45 miles.  A dog happily carried 20 pounds for 20 miles.\n",
      "\n",
      "Assistant:\n",
      "## FUNCTION_CALL ##\n",
      "{\n",
      "  \"function\": \"run_linear_trend_model\",\n",
      "  \"parameters\": {\n",
      "    \"x\": [20, 25, 45, 20],\n",
      "    \"y\": [15, 30, 50, 20]\n",
      "  }\n",
      "}\n",
      "\n",
      "Example 2:\n",
      "The red box is 20 cubic feet in volume and weighed 20 pounds.  The blue box is 30 cubic feet in volume and weighed 15 pounds.  The purple box was 50 cubic feet in volume and weighed 12 pounds.  A green box was 5 cubic feet in volume and weighed 35 pounds.\n",
      "\n",
      "Assistant:\n",
      "## FUNCTION_CALL ##\n",
      "{\n",
      "  \"function\": \"run_linear_trend_model\",\n",
      "  \"parameters\": {\n",
      "    \"x\": [20, 30, 50, 5],\n",
      "    \"y\": [20, 15, 12, 35]\n",
      "  }\n",
      "}\n",
      "###\n",
      "\n",
      "\n",
      "Ok now here's the actual user's data:\n",
      "###\n",
      "In the bustling heart of New York City, near the iconic Times Square, a hot dog stand chain named \"CityDogs\" has made a name for itself. Founded in 2005, this humble hot dog stand started on the bustling streets of Manhattan and has since grown, weaving its savory aroma into the fabric of the city. Each of its stands, strategically placed, tells a story of New York's ever-evolving landscape and appetite.\n",
      "\n",
      "The original stand, located just 0.5 miles from the center, sits on Broadway Avenue and has the highest revenue of $15,000 a month, thanks to the non-stop flow of tourists and city-dwellers alike. As one moves further away, the second outlet is nestled 1.5 miles out in the charming West Village on Bleecker Street, pulling in a respectable $12,500 monthly. Heading 3 miles out, the third stand resides in the hip enclave of Williamsburg, Brooklyn, on Bedford Avenue, where it enjoys a monthly revenue of $10,000, catering to the young and artsy crowd. At 4.2 miles from the city's core, the fourth stand in Astoria, Queens, on Ditmars Boulevard, manages to net $7,500 per month. Lastly, the fifth and furthest stand, 6 miles away in the scenic Bay Ridge, Brooklyn, on 3rd Avenue, garners $6,000 monthly, serving both locals and those eager for a waterfront view with their meal.\n",
      "\n",
      "As \"CityDogs\" continues to flourish, each location becomes a testament to New York's diverse population and their unifying love for a good hot dog. Whether it's the neon lights of Broadway or the quieter streets of Bay Ridge, these stands offer more than just a quick bite. They offer a slice of the city's soul, where distance and revenue intertwine in a dance as dynamic as New York itself.\n",
      "###\n",
      "\n",
      "Now, generate a function call that computes a linear regression, as defined in the FUNCTIONS. \n",
      "\n",
      "Assistant:\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#: Establish the Prompt template from the text file.\n",
    "linear_trend_prompt_template = PromptTemplate(linear_trend_prompt)\n",
    "\n",
    "#: Fill the prompt using our \n",
    "linear_trend_filled_prompt = linear_trend_prompt_template.fill(\n",
    "    FUNCTIONS=str(FUNCTIONS), \n",
    "    user_data=city_dogs\n",
    ")\n",
    "print(f\"linear_trend_filled_prompt: {linear_trend_filled_prompt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = json.dumps({\"prompt\": linear_trend_filled_prompt, \"max_tokens_to_sample\": 500})\n",
    "modelId = \"anthropic.claude-v2\" \n",
    "accept = \"application/json\"\n",
    "contentType = \"application/json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Here is the function call to run a linear regression on the data provided:\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"function\": \"run_linear_trend_model\", \n",
      "  \"parameters\": {\n",
      "    \"x\": [0.5, 1.5, 3, 4.2, 6],\n",
      "    \"y\": [15000, 12500, 10000, 7500, 6000]\n",
      "  }\n",
      "}\n",
      "```\n",
      "\n",
      "I extracted the distances in miles from Times Square for each location as the x values, and the monthly revenues in dollars for each location as the y values. This allows fitting a linear regression model to analyze the relationship between distance from Times Square and revenue.\n"
     ]
    }
   ],
   "source": [
    "response = bedrock_runtime.invoke_model(\n",
    "    body=body, modelId=modelId, accept=accept, contentType=contentType\n",
    ")\n",
    "response_body = json.loads(response.get(\"body\").read())\n",
    "\n",
    "print(response_body.get(\"completion\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = FunctionParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bedrock",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
