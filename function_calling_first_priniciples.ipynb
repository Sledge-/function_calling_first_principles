{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import boto3\n",
    "from utils import bedrock, print_ww\n",
    "from utils.utils import extract_model_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up Bedrock API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create new client\n",
      "  Using region: None\n",
      "boto3 Bedrock client successfully created!\n",
      "bedrock(https://bedrock.us-east-1.amazonaws.com)\n"
     ]
    }
   ],
   "source": [
    "boto3_bedrock = bedrock.get_bedrock_client(\n",
    "    assumed_role=os.environ.get(\"BEDROCK_ASSUME_ROLE\", None),\n",
    "    region=os.environ.get(\"AWS_DEFAULT_REGION\", None),\n",
    "    runtime=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's take a look at which models we have access to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extract_model_info(all_models): [('Titan Text Large', 'amazon.titan-tg1-large'), ('Titan Text Embeddings', 'amazon.titan-e1t-medium'), ('Titan Text Embeddings v2', 'amazon.titan-embed-g1-text-02'), ('Titan Text G1 - Express', 'amazon.titan-text-express-v1'), ('Titan Embeddings G1 - Text', 'amazon.titan-embed-text-v1'), ('Stable Diffusion XL', 'stability.stable-diffusion-xl'), ('Stable Diffusion XL', 'stability.stable-diffusion-xl-v0'), ('J2 Grande Instruct', 'ai21.j2-grande-instruct'), ('J2 Jumbo Instruct', 'ai21.j2-jumbo-instruct'), ('Jurassic-2 Mid', 'ai21.j2-mid'), ('Jurassic-2 Mid', 'ai21.j2-mid-v1'), ('Jurassic-2 Ultra', 'ai21.j2-ultra'), ('Jurassic-2 Ultra', 'ai21.j2-ultra-v1'), ('Claude Instant', 'anthropic.claude-instant-v1'), ('Claude', 'anthropic.claude-v1'), ('Claude V1 100k', 'anthropic.claude-v1-100k'), ('Claude', 'anthropic.claude-v2'), ('Claude V2 100k', 'anthropic.claude-v2-100k'), ('Command', 'cohere.command-text-v14')]\n"
     ]
    }
   ],
   "source": [
    "all_models = boto3_bedrock.list_foundation_models()\n",
    "print(f\"extract_model_info(all_models): {extract_model_info(all_models)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create new client\n",
      "  Using region: None\n",
      "boto3 Bedrock client successfully created!\n",
      "bedrock-runtime(https://bedrock-runtime.us-east-1.amazonaws.com)\n"
     ]
    }
   ],
   "source": [
    "bedrock_runtime = bedrock.get_bedrock_client(\n",
    "    assumed_role=os.environ.get(\"BEDROCK_ASSUME_ROLE\", None),\n",
    "    region=os.environ.get(\"AWS_DEFAULT_REGION\", None)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_data = \"\"\"\n",
    "Human: Tell me everything you know about JSON schema.\n",
    "\n",
    "Assistant:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = json.dumps({\"prompt\": prompt_data, \"max_tokens_to_sample\": 500})\n",
    "modelId = \"anthropic.claude-v2\" \n",
    "accept = \"application/json\"\n",
    "contentType = \"application/json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Here is a summary of what I know about JSON schema:\n",
      "\n",
      "- JSON schema is a specification for defining the structure and validation constraints of JSON data. It provides a declarative way to specify requirements for JSON documents.\n",
      "\n",
      "- The main purposes of JSON schema are to validate JSON data based on a predefined schema, provide auto-generated documentation, and assist in rapid development by providing auto-completion in code editors.\n",
      "\n",
      "- A JSON schema is itself a JSON document that declares constraints on the structure of other JSON documents. It defines things like required properties, data types, string lengths, validation patterns, etc.\n",
      "\n",
      "- Some of the basic keywords and concepts in JSON schema include:\n",
      "\n",
      "- type - specifies the JSON data type such as string, number, object, array, etc.\n",
      "\n",
      "- properties - defines the keys and value types for JSON objects\n",
      "\n",
      "- required - specifies required properties within an object\n",
      "\n",
      "- minimum/maximum - specifies the min and max value of a number\n",
      "\n",
      "- minLength/maxLength - specifies the min and max length of a string\n",
      "\n",
      "- pattern - defines a regular expression pattern that a string value must match\n",
      "\n",
      "- enum - restricts values to a fixed set of options\n",
      "\n",
      "- $ref - allows referencing definitions in external schema files\n",
      "\n",
      "- Multiple schemas can be combined using keywords like allOf, anyOf, oneOf, not to apply additional constraints.\n",
      "\n",
      "- There are several parsers and validator libraries available to validate JSON data against schemas. Popular ones include AJV, jsonschema, and is-my-json-valid.\n",
      "\n",
      "- JSON schema is commonly used for configuration files, API definitions, JSON LD data modeling, and anywhere that validation of structured JSON data is needed.\n"
     ]
    }
   ],
   "source": [
    "response = bedrock_runtime.invoke_model(\n",
    "    body=body, modelId=modelId, accept=accept, contentType=contentType\n",
    ")\n",
    "response_body = json.loads(response.get(\"body\").read())\n",
    "\n",
    "print(response_body.get(\"completion\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_data = \"\"\"\n",
    "Human: Can you explain to me your prompting structure?  I see the Human and Assistant designations.  What else can you tell me about how to talk to you?\n",
    "\n",
    "Assistant:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = json.dumps({\"prompt\": prompt_data, \"max_tokens_to_sample\": 500})\n",
    "modelId = \"anthropic.claude-v2\" \n",
    "accept = \"application/json\"\n",
    "contentType = \"application/json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I don't actually have a complex prompting structure. I'm an AI assistant created by Anthropic to be helpful, harmless, and honest. The \"Human\" and \"Assistant\" labels are there to clarify who is speaking, but you can just speak to me conversationally.\n"
     ]
    }
   ],
   "source": [
    "response = bedrock_runtime.invoke_model(\n",
    "    body=body, modelId=modelId, accept=accept, contentType=contentType\n",
    ")\n",
    "response_body = json.loads(response.get(\"body\").read())\n",
    "\n",
    "print(response_body.get(\"completion\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_data = \"\"\"\n",
    "Human: Your role is to form function arguments based on the specification provide in 'FUNCTIONS'.  Users will ask you a question about the weather, and you'll attempt to form the function call that we can pass along to a tool to determine the response. Do not try to answer questions about the weather directly, use the provided tools.  The tools are specified using a json schema format, which defines how the arguments to the function are to be formed.\n",
    "\n",
    "FUNCTIONS = [\n",
    "    {\n",
    "        \"name\": \"get_current_weather\",\n",
    "        \"description\": \"Get the current weather\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                },\n",
    "                \"format\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                    \"description\": \"The temperature unit to use. Infer this from the users location.\",\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"location\", \"format\"],\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "Examples\n",
    "###\n",
    "Human: \n",
    "What's the weather like in Glasgow Scotland?\n",
    "Assistant:\n",
    "'function_call': {'name': 'get_current_weather',\n",
    "    'arguments': '{\n",
    "        \"location\": \"Glasgow, Scotland\",\n",
    "        \"format\": \"celsius\"\n",
    "    }'\n",
    "}\n",
    "\n",
    "Human: \n",
    "What's the weather like in Raleigh, NC?\n",
    "Assistant:\n",
    "'function_call': {'name': 'get_current_weather',\n",
    "    'arguments': '{\n",
    "        \"location\": \"Raleigh, North Carolina\",\n",
    "        \"format\": \"fahrenheit\"\n",
    "    }'\n",
    "}\n",
    "###\n",
    "\n",
    "Human:\n",
    "What's the weather like in Washington, DC?\n",
    "\n",
    "Assistant:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = json.dumps({\"prompt\": prompt_data, \"max_tokens_to_sample\": 500})\n",
    "modelId = \"anthropic.claude-v2\" \n",
    "accept = \"application/json\"\n",
    "contentType = \"application/json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Here is the function call to get the current weather in Washington, DC:\n",
      "\n",
      "'function_call': {'name': 'get_current_weather', \n",
      "    'arguments': '{\n",
      "        \"location\": \"Washington, DC\",  \n",
      "        \"format\": \"fahrenheit\"\n",
      "    }'\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = bedrock_runtime.invoke_model(\n",
    "    body=body, modelId=modelId, accept=accept, contentType=contentType\n",
    ")\n",
    "response_body = json.loads(response.get(\"body\").read())\n",
    "\n",
    "print(response_body.get(\"completion\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# And Now for the Main Event.\n",
    "\n",
    "Here's a class that prompts a language model for function arguments for a linear regression, based on data that we load into the context from and external source.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompt_template import PromptTemplate, load_text_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #: Test using linear_trend_request_prompt.txt\n",
    "    linear_trend_prompt = load_text_file('linear_trend_request_prompt.txt')\n",
    "    linear_trend_prompt_template = PromptTemplate(linear_trend_prompt)\n",
    "    # print(f\"linear_trend_prompt_template.template: {linear_trend_prompt_template.template}\")\n",
    "    linear_trend_filled_prompt = linear_trend_prompt_template.fill(functions=\"<< add your function definitions here >>\", \n",
    "    user_data=\"Here's a story involving some interesting commentary around trends in a market, supported by quantitative data.\")\n",
    "    print(f\"linear_trend_filled_prompt: {linear_trend_filled_prompt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bedrock",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
